---
layout: post
title: Как у нас сломался Ceph
date: '2017-10-13T10:15:00.000-07:00'
author: Simple Pleasure
tags:
- true story
modified_time: '2017-10-13T13:40:55.347-07:00'
blogger_id: tag:blogger.com,1999:blog-1992588495677931791.post-7283289331615083965
blogger_orig_url: http://linuxmates.blogspot.com/2017/10/ceph.html
---

<div dir="ltr" style="text-align: left;" trbidi="on">Детектив в 1 части.<br /><br />Есть Ceph версии 0.94 (Hammer). 6 стораджей, 8 мониторов, по 4-6 OSD на каждом сторадже, SSD диски объемом от 1 ТБ до 4 ТБ. Реплика - 2, минимум 1.<br /><br />Как-то раз случилось такое: вечером прошел некий шторм по всему кластеру и самопроизвольно перезапустилось множество OSD. В логах osd были видны стандартные для ceph ошибки вида `no reply from osd.X`. Немного slow requests и сампроизвольные рестарты. К сожалению, не все перезапустившиеся osd смогли подняться. А именно пала героем osd.45 на storage6.<br /><br />Мы решили, что это нестрашно, ведь это всего 1 из 44 osd, и пробовали запустить ее разными способами. Ну знаете, umount/mount директории, flush и пересоздание журнала и т.д. В итоге, как обычно в таких ситуациях поступает любой админ, дело кончилось перезапуском всей ноды, так как такое бывает, что systemd немножко сходит с ума и не хочет корректно запускать нужные процессы.<br /><br />И после перезапуска мы уже имели 4 мертвых osd, т.е. все на этом сторадже. Ошибки такие же, как и на первичной osd:<br /><br /><pre class="brush: js">017-10-12 12:10:01.756562 7f02459af880&nbsp; 0 ceph version 0.94.10 (b1e0532418e4631af01acbc0cedd426f1905f4af), process ceph-osd, pid 2343<br />2017-10-12 12:10:01.767719 7f02459af880&nbsp; 0 filestore(/var/lib/ceph/osd/ceph-45) backend xfs (magic 0x58465342)<br />2017-10-12 12:10:01.769302 7f02459af880&nbsp; 0 genericfilestorebackend(/var/lib/ceph/osd/ceph-45) detect_features: FIEMAP ioctl is supported and appears to work<br />2017-10-12 12:10:01.769310 7f02459af880&nbsp; 0 genericfilestorebackend(/var/lib/ceph/osd/ceph-45) detect_features: FIEMAP ioctl is disabled via 'filestore fiemap' config option<br />2017-10-12 12:10:01.785177 7f02459af880&nbsp; 0 genericfilestorebackend(/var/lib/ceph/osd/ceph-45) detect_features: syncfs(2) syscall fully supported (by glibc and kernel)<br />2017-10-12 12:10:01.785229 7f02459af880&nbsp; 0 xfsfilestorebackend(/var/lib/ceph/osd/ceph-45) detect_feature: extsize is disabled by conf<br />2017-10-12 12:10:01.788289 7f02459af880&nbsp; 0 filestore(/var/lib/ceph/osd/ceph-45) mount: enabling WRITEAHEAD journal mode: checkpoint is not enabled<br />2017-10-12 12:10:01.790182 7f02459af880 -1 journal FileJournal::_open: disabling aio for non-block journal.&nbsp; Use journal_force_aio to force use of aio anyway<br />2017-10-12 12:10:01.790184 7f02459af880&nbsp; 1 journal _open /var/lib/ceph/osd/ceph-45/journal fd 19: 10485760000 bytes, block size 4096 bytes, directio = 1, aio = 0<br />2017-10-12 12:10:01.790428 7f02459af880&nbsp; 1 journal _open /var/lib/ceph/osd/ceph-45/journal fd 19: 10485760000 bytes, block size 4096 bytes, directio = 1, aio = 0<br />2017-10-12 12:10:01.790923 7f02459af880&nbsp; 0 &lt;cls&gt; cls/hello/cls_hello.cc:271: loading cls_hello<br />2017-10-12 12:10:01.796251 7f02459af880&nbsp; 0 osd.45 19681 crush map has features 1107558400, adjusting msgr requires for clients<br />2017-10-12 12:10:01.796260 7f02459af880&nbsp; 0 osd.45 19681 crush map has features 1107558400 was 8705, adjusting msgr requires for mons<br />2017-10-12 12:10:01.796263 7f02459af880&nbsp; 0 osd.45 19681 crush map has features 1107558400, adjusting msgr requires for osds<br />2017-10-12 12:10:01.796273 7f02459af880&nbsp; 0 osd.45 19681 load_pgs<br />2017-10-12 12:10:01.850570 7f02459af880 -1 *** Caught signal (Aborted) **<br />&nbsp;in thread 7f02459af880<br /><br />&nbsp;ceph version 0.94.10 (b1e0532418e4631af01acbc0cedd426f1905f4af)<br />&nbsp;1: /usr/bin/ceph-osd() [0xb35f7d]<br />&nbsp;2: (()+0x11390) [0x7f0244897390]<br />&nbsp;3: (gsignal()+0x38) [0x7f0242c8f428]<br />&nbsp;4: (abort()+0x16a) [0x7f0242c9102a]<br />&nbsp;5: (__gnu_cxx::__verbose_terminate_handler()+0x16d) [0x7f02435d284d]<br />&nbsp;6: (()+0x8d6b6) [0x7f02435d06b6]<br />&nbsp;7: (()+0x8d701) [0x7f02435d0701]<br />&nbsp;8: (()+0x8d919) [0x7f02435d0919]<br />&nbsp;9: (object_info_t::decode(ceph::buffer::list::iterator&amp;)+0xb7a) [0x7b47ba]<br />&nbsp;10: (object_info_t::object_info_t(ceph::buffer::list&amp;)+0x1b7) [0x78cd07]<br />&nbsp;11: (PGLog::read_log(ObjectStore*, coll_t, coll_t, ghobject_t, pg_info_t const&amp;, std::map&lt;eversion_t, hobject_t, std::less&lt;eversion_t&gt;, std::allocator&lt;std::pair&lt;eversion_t const, hobject_t&gt; &gt; &gt;&amp;, PGLog::IndexedLog&amp;, pg_missing_t&amp;, std::__cxx11::basic_ostringstream&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;&amp;, std::set&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::less&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt;*)+0xf52) [0x784c82]<br />&nbsp;12: (PG::read_state(ObjectStore*, ceph::buffer::list&amp;)+0x24e) [0x81791e]<br />&nbsp;13: (OSD::load_pgs()+0xbb6) [0x6b9eb6]<br />&nbsp;14: (OSD::init()+0x137f) [0x6bdddf]<br />&nbsp;15: (main()+0x2c20) [0x646310]<br />&nbsp;16: (__libc_start_main()+0xf0) [0x7f0242c7a830]<br />&nbsp;17: (_start()+0x29) [0x65c779]<br />&nbsp;NOTE: a copy of the executable, or `objdump -rdS &lt;executable&gt;` is needed to interpret this.<br /></pre><br />Если стартовать osd напрямую через бинарь, а не через upstart или systemctl, то можно увидеть выбрасываемое исключение и немного побольше инфы:<br /><pre class="brush: js">root@storage6:~# /usr/bin/ceph-osd -f --cluster ceph --id 45<br />starting osd.45 at :/0 osd_data /var/lib/ceph/osd/ceph-45 /var/lib/ceph/osd/ceph-45/journal<br />2017-10-12 15:13:45.288995 7fc5b1b06880 -1 osd.45 22551 log_to_monitors {default=true}<br />terminate called after throwing an instance of 'ceph::buffer::malformed_input'<br />&nbsp; what():&nbsp; buffer::malformed_input: __PRETTY_FUNCTION__ decode past end of struct encoding<br />*** Caught signal (Aborted) **<br />&nbsp;in thread 7fc58e699700<br />terminate called recursively<br />Aborted (core dumped)<br /></pre><div><br />Здесь мы видим, что демон ругается на какие-то неправильные входные данные. Ситуация осложняется тем, что в кластере появились такие объекты:<br /><pre class="brush: js">recovery 3/3102030 unfound (0.000%)<br /><br /></pre><br />4 osd через определенный таймаут были помечены как out. Началось восстановление, но в кластере было около 100 непроходящих slow requests. Так как Ceph используется Openstack'ом в качестве storage backend'а, клиенты это очень почувствовали и вся работа встала, так как виртуалки тормозили.<br /><br />В Ceph у нас два пула. Один для непосредственно дисков виртуалок - rbd1, второй - для имэджей, из которых создаются эти диски. Unfound объекты в данном случае критичны для обоих пулов, так как могут стать следствием неконсистентности данных. Но если в первом случае - все анфаунды в rbd1 - мы будем иметь максимум 3 фарша, то во втором случае - все анфаунды в images - мы потенциально имеем целый магазинчик фарша в связи с особенностями работы Openstack. Поэтому, так как мы в принципе были готовы потерять три машины, потому что опенстек - это не продакшн, требовалось проверить, к какому пулу относятся эти ненайденные объекты. Они все были на одной osd, в одной pg.</div><pre class="brush: js">root@volume1:~# ceph pg 2.67 list_missing<br />{<br />&nbsp; &nbsp; "offset": {<br />&nbsp; &nbsp; &nbsp; &nbsp; "oid": "",<br />&nbsp; &nbsp; &nbsp; &nbsp; "key": "",<br />&nbsp; &nbsp; &nbsp; &nbsp; "snapid": 0,<br />&nbsp; &nbsp; &nbsp; &nbsp; "hash": 0,<br />&nbsp; &nbsp; &nbsp; &nbsp; "max": 0,<br />&nbsp; &nbsp; &nbsp; &nbsp; "pool": -1,<br />&nbsp; &nbsp; &nbsp; &nbsp; "namespace": ""<br />&nbsp; &nbsp; },<br />&nbsp; &nbsp; "num_missing": 3,<br />&nbsp; &nbsp; "num_unfound": 3,<br />&nbsp; &nbsp; "objects": [<br />&nbsp; &nbsp; &nbsp; &nbsp; {<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "oid": {<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "oid": "rbd_data.8e53d86b8b4567.0000000000000220",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "key": "",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "snapid": -2,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "hash": 2391933031,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "max": 0,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "pool": 2,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "namespace": ""<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "need": "19232'24922826",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "have": "19172'24922749",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "locations": []<br />&nbsp; &nbsp; &nbsp; &nbsp; },<br />&nbsp; &nbsp; &nbsp; &nbsp; {<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "oid": {<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "oid": "rbd_data.42375f55c840f3.000000000000c6d3",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "key": "",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "snapid": -2,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "hash": 1598576743,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "max": 0,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "pool": 2,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "namespace": ""<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "need": "19229'24922824",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "have": "19110'24922274",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "locations": []<br />&nbsp; &nbsp; &nbsp; &nbsp; },<br />&nbsp; &nbsp; &nbsp; &nbsp; {<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "oid": {<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "oid": "rbd_data.b4b7816b8b4567.0000000000000298",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "key": "",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "snapid": -2,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "hash": 2351466599,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "max": 0,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "pool": 2,<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "namespace": ""<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "need": "19229'24922823",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "have": "19110'24921517",<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "locations": []<br />&nbsp; &nbsp; &nbsp; &nbsp; }<br />&nbsp; &nbsp; ],<br />&nbsp; &nbsp; "more": 0<br />}<br /><br /></pre>Все объекты в пуле 2, и это пул rbd1. Выдохнули. Если что мы теряем всего три виртуалки, это не так страшно.<br />Удаляем одну из проблемных osd из кластера с помощью `ceph osd rm osd.45`. Анфаундов становится 28. Это уже проблема. Нужно любым способом попытаться восстановить неработающие osd, или нас ждет полный ресетап всех виртуалок в Openstack, а это во-первых сложно, а во-вторых ужасно стыдно. В общем, мы врубили режим лютого дебага.<br /><br />Возможно, проблема с железом? Попросили техников в ДЦ добавить два 4ТБ диска в storage6. Налили на них Ceph...работает. Чудеса.<br />Конечно, мы сразу исключили все обновления и изменения в системе. Ничего не менялось за день до проблемы.<br /><br />Итак, что у нас есть в данный момент?<br />- по кластеру прошла какая-то аномалия, заставившая часть osd перезапуститься<br />- одна из них не смогла запуститься<br />- после рестарта ее ноды, не смогли запуститься оставшиеся osd<br />- в кластере есть заблокированные запросы, все на одной osd (8ая)<br />- в кластере есть unfound объекты (28 штук), все на той же самой osd (8ая)<br />- видимо, удаление из кластера остальных osd опять увеличит количество анфаундов, значит делать это не стоит<br />- клиенты страдают, рекавери периодически останавливается и приходится его триггерить перезапуском любой из работающих osd (дело в том, что кластер ceph иногда может залипать и переставать восстанавливаться. тогда нужно стриггерить восстановление событием: osd up-&gt;osd down-&gt;osd up)<br /><br /><br />Стрейсим запуск osd.45:<br /><pre class="brush: js">pidof `start ceph-osd id=45` | xargs strace -p 2&gt; 45-strace.log<br /><br /></pre>Видим, что osd спотыкается на чтении одного из участка локальных данных, после чего выбрасывается знакомое уже нам исключение `ceph::buffer::malformed_input`: <br /><pre class="brush: js">stat("/var/lib/ceph/osd/ceph-45/current/2.c_head", {st_mode=S_IFDIR|0755, st_size=24576, ...}) = 0<br />stat("/var/lib/ceph/osd/ceph-45/current/2.c_head/DIR_C", {st_mode=S_IFDIR|0755, st_size=24576, ...}) = 0<br />stat("/var/lib/ceph/osd/ceph-45/current/2.c_head/DIR_C/DIR_0", {st_mode=S_IFDIR|0755, st_size=24576, ...}) = 0<br />stat("/var/lib/ceph/osd/ceph-45/current/2.c_head/DIR_C/DIR_0/DIR_0", {st_mode=S_IFDIR|0755, st_size=24576, ...}) = 0<br />stat("/var/lib/ceph/osd/ceph-45/current/2.c_head/DIR_C/DIR_0/DIR_0/DIR_D", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0<br />stat("/var/lib/ceph/osd/ceph-45/current/2.c_head/DIR_C/DIR_0/DIR_0/DIR_D/DIR_B", 0x7ffcccfdf330) = -1 ENOENT (No such file or directory)<br />stat("/var/lib/ceph/osd/ceph-45/current/2.c_head/DIR_C/DIR_0/DIR_0/DIR_D/rbd\\udata.e1bde639901b63.0000000000000000__head_852BD00C__2", {st_mode=S_IFREG|0644, st_size=8388608, ...}) = 0<br />stat("/var/lib/ceph/osd/ceph-45/current/2.c_head/DIR_C/DIR_0/DIR_0/DIR_D/rbd\\udata.e1bde639901b63.0000000000000000__head_852BD00C__2", {st_mode=S_IFREG|0644, st_size=8388608, ...}) = 0<br />open("/var/lib/ceph/osd/ceph-45/current/2.c_head/DIR_C/DIR_0/DIR_0/DIR_D/rbd\\udata.e1bde639901b63.0000000000000000__head_852BD00C__2", O_RDWR) = 22<br />fgetxattr(22, "user.ceph._", 0x7ffcccfdf7c0, 100) = -1 ERANGE (Numerical result out of range)<br />fgetxattr(22, "user.ceph._", NULL, 0)&nbsp; &nbsp;= 250<br />fgetxattr(22, "user.ceph._", "\17\10\r\1\0\0\4\3I\0\0\0\0\0\0\0(\0\0\0rbd_data.e1bde639901b63.0000000000000000\376\377\377\377\377\377\377\377\f\320+\205\0\0\0\0\0\2\0\0\0\0\0\0\0\6\3\34\0\0\0\2\0\0\0\0\0\0\0\377\377\377\377\0\0\0\0\0\0\0\0\377\377\377\377\377\377\377\377\0\0\0\0M\311\274\2\0\0\0\0\34K\0\0L\311\274\2\0\0\0\0\34K\0\0\2\2\25\0\0\0\10h\361\374\0\0\0\0\0\341\244\v\0\0\0\0\0\0\0\0\0\0\0\200\0\0\0\0\0\265?\336Y\256\270N\5\2\2\25\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0M\311\274\2\0\0\0\0\0\0\0", 250) = 250<br />futex(0x7f963ba19680, FUTEX_WAKE_PRIVATE, 2147483647) = 0<br />write(2, "terminate called after throwing "..., 48) = 48<br />write(2, "ceph::buffer::malformed_input", 29) = 29<br />write(2, "'\n", 2)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = 2<br />write(2, "&nbsp; what():&nbsp; ", 11)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= 11<br />write(2, "buffer::malformed_input: __PRETT"..., 79) = 79<br />write(2, "\n", 1)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= 1<br />rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0<br />tgkill(23708, 23708, SIGABRT)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= 0<br />--- SIGABRT {si_signo=SIGABRT, si_code=SI_TKILL, si_pid=23708, si_uid=0} ---<br />write(2, "*** Caught signal (Aborted) **\n "..., 55) = 55<br />futex(0x7f963b802110, FUTEX_WAKE_PRIVATE, 2147483647) = 0<br />write(2, " ceph version 0.94.10 (b1e053241"..., 1418) = 1418<br />futex(0x48d40b4, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x48d40b0, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1<br />futex(0x48d4030, FUTEX_WAKE_PRIVATE, 1) = 1<br />futex(0x48d4058, FUTEX_WAIT_PRIVATE, 2, NULL) = 0<br /><div><br /></div><br /></pre><div><br /></div><div>Возможно, битый объект, думаем мы. Ищем его реплику на других стораджах:</div><div></div><div></div><pre class="brush: js">find /mnt/osd? -name *e1bde639901b63.0000000000000000__head_852BD00C*</pre><div><div>Находим его на storage5 у osd.37. Сверяем md5-сумму. Одинаковая. Ну может xattr`ы отличаются? Аккуратно копируем rsync'ом объект с storage5 на storage6 с сохранением всей Мета-информации. Бэкапим оригинальный файл и заменяем его скопированным. Пробуем запустить, но безрезультатно - всё то же самое. Но ведь там osd работает! Как же так?</div><div><br /></div><div>Углубляемся в изучение исходного кода демонов и ищем, из-за чего он может валиться. Тут на этом этапе нам уже помогает C++ разработчик.&nbsp;</div><div>Понятно, что проблема в данных, извлекаемых при boot-процессе osd. Пробуем запускать другие, здоровые osd и стрейсим их, чтобы понять, как же они должны по-нормальному работать. Запускаем заболевшие osd через gdb и пытаемся в дебаг.</div><div><br /></div><div>Через несколько часов разработчик говорит, что понимает, в чем разница старта osd и на каком участке кода он валится, но непонятна первопричина такого поведения. Говорит, что 37ая osd (с которой мы скопировали "валидный" объект) тогда тоже не должна работать. Предлагает ее перезапустить, чтобы доказать гипотезу. Мы в отказ. Мол и так все плохо, а там вообще другая нода, как бы хуже не было от этого. Разработчик же говорит логичную вещь, что это все равно не дело, что оно там работает на соплях и в любой момент может упасть и не подняться, а так хоть мы продвинемся дальше. Согласны, рестартуем, не поднимается. Разработчику - счастье, нам - траур, так как анфаундов стало больше, а количество slow requests увеличилось до 800. Но что поделать.</div><div><br /></div><div>Теперь у нас есть потенциально два полных стораджа, osd на которых висят на волоске и сотавшиеся 3 запущенных osd на storage5 перезапуска не выдержат.&nbsp;</div><div>Начинаем сравнивать файловые системы и структуры файлов на здоровых osd, так как видим разницу в старте. Находим, что дело как будто бы кроется в xattr'ах и работе с ними. Для уточнения стрейсим здоровую osd:</div><div></div><pre class="brush: js">pidof `start ceph-osd id=8` | awk {'print $1'} | xargs strace -fe open,fsetxattr -p&nbsp; 2&gt;8-osd-xattr.strace</pre></div><div><br /></div><div>Много, конечно, не дает, но видим, что xattr`а почему-то распределены иначе. Разработчик смотрит в разные версии Ceph (9ую и 10ую) и видит, что в 10й как раз есть нужные нам фиксы, которые поволят корректно пройти процесс запуска и чтения файловой системы. Предлагает запатчить и собрать Ceph самим, потом подложить бинарь и попробовать запустить хотя бы один больной osd. Мы уже грустно представляем, что нас ждет, и тут он невзначай говорит скорее в шутку: "Слушайте, ребят, а вы случайно не ставили тут никогда 10й Ceph?" И смеется. Админ отвечает: "Да, случайно ставили, потом паппет переустановил нужную версию". Секунда тишины. И все начинают ржать.</div><div><br /></div><div>А дело было вот в чем: storage[56] наливались самыми последними, в момент их сетапа из отдельного окружения были некорректно указаны apt pins, из-за чего поставилась дефолтная версия Ceph из убунтовских реп. Паппет прикатил ее, накатил osd, запустил их, они начали работать. Спустя сутки админ заметил, что версия Ceph неправильная, внес изменения, установил верную, перезапустил (!!!) osd (не переналивая) и ушел курить бамбук. Спустя две недели произошел непонятный катаклизм, описанный в самом начале, из-за чего произошло нечто, и osd не поднялась.</div><div><br /></div><div>Разработчик еще в середине смотрел на файловые структуры и не понимал, почему они такие странные, и списывал на возможные коррапты данных. Оказалось, что ребята из Ceph в 10й версии изменили способ хранения и представления xattr'ов. Дело в том, что они раньше хранили все значения xattr'ов inline, но это было неоптимально и имело ограничение по длине. Соответственно, в 10й версии они изменили структуру хранения и стали хранить их блоками, разбив на несколько частей. Osd инициализировалась на 10й версии и проработала так сутки, создав объекты "по-новому", потом ее даунгрейдили, и она так проработала еще 2 недели. Почему она запустилась после даунгрейда - непонятно. Возможно, никогда не доходила до этих данных. Но в нашем случае она натыкалась на эти xattr'ы и не могла их переварить, выбрасывая исключение malformed_input.&nbsp;</div><div><br /></div><div>Мы, конечно же, тут же установили на storage[56] Jewel версии Ceph'а, и все osd как миленькие запустились. Анфаунды также ушли, заблокированные запросы тоже исчезли. Ceph начал восстанавливаться. Все в компании уже были почти уверены, что потеряют весь опенстек (я дал прогноз, что с вероятностью в 70 процентов, мы потеряем все данные). И вот как получилось затащить. Конечно, большое спасибо разработчику, он очень помог.</div><div><br /></div><div><br /></div><div>Такая вот история. Через пару часов после возникновения проблемы один админ сказал, что узнал исключение, выбрасываемое демоном и пошел смотреть в код, а там <i>всего </i>23 места, где оно может быть выброшено. Я посмеялся и сказал, что это много и неправильный подход, так как мы все равно не будем пересобирать Ceph. В тот момент для меня это было дико. Но когда я понял, что лучшего выхода нет, это показалось мне неплохим шансом, который можно было использовать.&nbsp;</div><div><br />И в итоге подход "а давайте палить в сырцы, чтобы понимать, что происходит и что происходит не так" оказался очень эффективным, я был не прав.   </div></div>