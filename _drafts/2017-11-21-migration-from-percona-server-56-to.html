---
layout: post
title: Migration from Percona Server 5.6 to Percona Xtradb Cluster
date: '2017-11-21T07:53:00.000-08:00'
author: Simple Pleasure
tags: 
modified_time: '2017-11-21T07:53:12.143-08:00'
blogger_id: tag:blogger.com,1999:blog-1992588495677931791.post-1424061228900666453
blogger_orig_url: http://linuxmates.blogspot.com/2017/11/migration-from-percona-server-56-to.html
---

<div dir="ltr" style="text-align: left;" trbidi="on"><div dir="ltr" style="text-align: left;" trbidi="on"><div dir="ltr" style="text-align: left;" trbidi="on"><div dir="ltr" style="text-align: left;" trbidi="on"><div dir="ltr" style="text-align: left;" trbidi="on"><div dir="ltr" style="text-align: left;" trbidi="on"><div dir="ltr" style="text-align: left;" trbidi="on"><div dir="ltr" style="text-align: left;" trbidi="on">Today I want to tell you how to migrate from MySQL Percona Server 5.6 to Percona Xtradb Cluster.<br /><br />My initial configuration was:<br />- standard mysql master-slave replication<br />- node1 is a master<br />- node2 is a slave<br /><br />Now I need to setup master-master replication for failover purposes. But before all we need to add one more server in our configuration. I choose a scheme where only two mysql-servers act as primary and the third acts as an arbitrator and doesn't store any data, because percona has synchronous replication (what means a data is not written at all while it is not written on ALL nodes in cluster) and the latency of a cluster is equal to latency of the slowest node in the cluster, I don't want add one more point of possible latency and don't need to store a third replica of a data. So on the third node I will just install and configure Galera Arbitrator. I hope you understand purposes, why you should have minimum 3 members in cluster (hint: avoiding split-brain).<br /><br />Our action plan consists of these parts:<br />1. Update a slave to xtradb node<br />2. Setup xtradb cluster on the slave node continuing to receive any updates from master<br />3. Configure Galera Arbitrator on a third node (node3) and join it in cluster with node2<br />4. Shutdown an application targeting on master mysql node<br />5. Monitor a replication lag, wait until it disappears.<br />6. Stop and reset slave node (node2)<br />7. Point the application to node2<br />8. Update the former master to xtradb node<br />9. Join node1 into cluster<br /><br />Let's begin.<br /><br />Before all works please shure that your replication works fine and the data really replicates. You can use command: <br /><pre class="brush: bash">mysql -u root -e 'show slave status\G;'<br /></pre>1. Update a slave to xtradb node<br /><br /></div><pre class="brush: bash">systemctl stop mysql<br />apt-get remove percona-server-server-5.6 percona-server-client-5.6<br />apt-get install percona-xtradb-cluster-server-5.6<br /></pre>After these steps mysql database should normal start. If you have some similar output and mysql doesn't start: <br /><pre class="brush: bash">Building dependency tree...<br />Reading state information...<br />percona-xtradb-cluster-server-5.6 is already the newest version.<br />The following packages were automatically installed and are no longer required:<br />  libhtml-template-perl libio-socket-ssl-perl libnet-libidn-perl<br />  libnet-ssleay-perl libperconaserverclient18.1 libterm-readkey-perl<br />  percona-server-common-5.6<br />Use 'apt-get autoremove' to remove them.<br />0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.<br />1 not fully installed or removed.<br />After this operation, 0 B of additional disk space will be used.<br />Setting up percona-xtradb-cluster-server-5.6 (5.6.37-26.21-3.jessie) ...<br /><br /><br /> * Percona XtraDB Cluster is distributed with several useful UDF (User Defined Function) from Percona Toolkit.<br /> * Run the following commands to create these functions:<br /><br />        mysql -e "CREATE FUNCTION fnv1a_64 RETURNS INTEGER SONAME 'libfnv1a_udf.so'"<br />        mysql -e "CREATE FUNCTION fnv_64 RETURNS INTEGER SONAME 'libfnv_udf.so'"<br />        mysql -e "CREATE FUNCTION murmur_hash RETURNS INTEGER SONAME 'libmurmur_udf.so'"<br /><br /> * See http://www.percona.com/doc/percona-xtradb-cluster/5.6/management/udf_percona_toolkit.html for more details<br /><br /><br />Job for mysql.service failed. See 'systemctl status mysql.service' and 'journalctl -xn' for details.<br />invoke-rc.d: initscript mysql, action "start" failed.<br />dpkg: error processing package percona-xtradb-cluster-server-5.6 (--configure):<br /> subprocess installed post-installation script returned error exit status 1<br />Errors were encountered while processing:<br /> percona-xtradb-cluster-server-5.6<br />E: Sub-process /usr/bin/dpkg returned an error code (1)<br /></pre>Remove newly installed Percona packages and libmysqlclient and then reinstall the packages: <br /><pre class="brush: bash">root@node2:~# dpkg --get-selections | grep -i mysql<br />libdbd-mysql-perl    install<br />libmysqlclient18:amd64    install<br />mysql-common     install<br />root@node2:~# apt-get remove percona-xtradb-cluster-client-5.6 percona-xtradb-cluster-server-5.6 libmysqlclient18<br /></pre>This hint should you help. After mysql has been started, check replication status, that all works as expected. Now we will configure the node2 as a 1 node cluster. 2. Setup xtradb cluster on the slave node continuing to receive any updates from master Create and open file named <b>/etc/mysql/conf.d/pxc_cluster.cnf</b> and write the next configuration: <br /><pre class="brush: bash">[mysqld]<br />binlog_format = ROW<br />default_storage_engine = InnoDB<br />innodb_autoinc_lock_mode = 2<br />innodb_locks_unsafe_for_binlog = 1<br />wsrep_cluster_address = gcomm://<br />wsrep_cluster_name = my_unicorn_cluster<br />wsrep_node_address = 10.13.200.2<br />wsrep_node_name = node2<br />wsrep_provider = /usr/lib/libgalera_smm.so<br />wsrep_sst_auth = sst:secret<br />wsrep_sst_method = xtrabackup-v2<br /></pre>All important parameters are described here. Several of them I will explain: <b>wsrep_cluster_address</b> - cluster address. Here we defined no IP address, which means that node is allowed to build a cluster all by itself alone. Later we will change this parameter. <b>wsrep_node_address</b> - node2's IP <b>wsrep_sst_auth</b> - the most important setting, which could save your time later. For a SST (state snapshot transfer - actually just a full backup) we need create a user on future primary (alone) node2, which will be the first node in the cluster. It's obvious, that <i>sst</i> is its name and <i>secret</i> is its password. <b>wsrep_sst_method</b> - to make, transfer and apply a snapshot on donor (in our case this would be node2) and joiner node (current acts as a master, would be node1) I'm using xtrabackup-v2. You can choose different methods, but then configuration can different.<br />Okay, now <b>restart mysql </b>and apply the changes.<br /><br />We need to do the last 2 things: create a mysql user <i>sst</i>&nbsp;with proper privileges and check our cluster state.<br />To create the user execute following SQL-commands:<br /><br /></div><pre class="brush: bash">[mysqld]<br />mysql@node2&gt; CREATE USER 'sstuser'@'localhost' IDENTIFIED BY 'secret';<br />mysql@node2&gt; GRANT PROCESS, RELOAD, LOCK TABLES, REPLICATION CLIENT ON *.* TO 'sst'@'localhost';<br />mysql@node2&gt; FLUSH PRIVILEGES;<br /></pre>Our ex-slave now is fully ready.<br /><div>3. Configure Galera Arbitrator on a third node (node3) and join it in cluster with node2<br />To decrease possibly cluster latency due to disk I/O and network latency the node3 will be set as a Galera Arbitrator.&nbsp;</div><div>Install&nbsp;<span style="background-color: #f5f1e5; color: #333333; font-family: &quot;menlo&quot; , &quot;monaco&quot; , &quot;consolas&quot; , &quot;courier new&quot; , monospace; font-size: 13px;">percona-xtradb-cluster-garbd-5.7:</span></div><div><span style="background-color: #f5f1e5; color: #333333; font-family: &quot;menlo&quot; , &quot;monaco&quot; , &quot;consolas&quot; , &quot;courier new&quot; , monospace; font-size: 13px;"><br /></span></div></div><pre class="brush: bash"></pre></div>apt-get install percona-xtradb-cluster-garbd-5.7  Change file /etc/default/garbd: <br /><pre class="brush: bash"># Copyright (C) 2012 Codership Oy<br /># This config file is to be sourced by garb service script.<br /><br /># A comma-separated list of node addresses (address[:port]) in the cluster<br />GALERA_NODES="10.13.200.2:4567"<br /><br /># Galera cluster name, should be the same as on the rest of the nodes.<br />GALERA_GROUP="myreports_rc"<br /><br /># Optional Galera internal options string (e.g. SSL settings)<br /># see http://galeracluster.com/documentation-webpages/galeraparameters.html<br /># GALERA_OPTIONS=""<br /><br /># Log file for garbd. Optional, by default logs to syslog<br /># Deprecated for CentOS7, use journalctl to query the log for garbd<br /># LOG_FILE=""<br /></pre><pre class="brush: bash"></pre><pre class="brush: bash">Don't forget to remove a line in the file, else garbd will not start:</pre><pre class="brush: bash"></pre></div><pre># REMOVE THIS AFTER CONFIGURATION<br /></pre><pre>Start a daemon:</pre><pre></pre><pre></pre></div><pre class="brush: bash">service garbd start<br /></pre><pre class="brush: bash">journalctl -u garbd will show you the daemon logs and can be used for debug info.</pre></div></div>